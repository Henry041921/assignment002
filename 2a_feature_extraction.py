import cv2
import mediapipe as mp
import numpy as np
import os
import pandas as pd
import copy

# --- é…ç½®åŒº ---
# âš ï¸ è¿™é‡Œå¿…é¡»å¯¹åº”è€å¸ˆæä¾›çš„åŒ¿åæ•°æ®é›†æ–‡ä»¶å¤¹åå­—
DATA_DIR = "images"
# æˆ‘ä»¬ç»§ç»­ä½¿ç”¨è¿™ä¸ªæ–‡ä»¶åï¼Œè¿™æ ·åé¢çš„è®­ç»ƒä»£ç ä¸ç”¨æ”¹
OUTPUT_FILE = "landmarks_data.csv"

# åˆå§‹åŒ– MediaPipe Hands
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=True,  # å¤„ç†é™æ€å›¾ç‰‡æ¨¡å¼
    max_num_hands=1,  # åªå¤„ç†ä¸€åªæ‰‹
    min_detection_confidence=0.5
)


def normalize_landmarks(landmarks):
    """
    ğŸŒŸ æ ¸å¿ƒå¾—åˆ†ç‚¹ (Part 2b): æ•°æ®å½’ä¸€åŒ– (Data Pre-processing)
    é€»è¾‘ï¼š
    1. ç›¸å¯¹åæ ‡ï¼šå°†æ‰€æœ‰ç‚¹å‡å»æ‰‹è…•(ç‚¹0)çš„åæ ‡ã€‚è¿™æ ·æ— è®ºæ‰‹åœ¨ç”»é¢å“ªé‡Œï¼Œç‰¹å¾éƒ½ä¸€æ ·ã€‚
    2. å°ºåº¦å½’ä¸€åŒ–ï¼šé™¤ä»¥æœ€å¤§ç»å¯¹å€¼ã€‚è¿™æ ·æ— è®ºæ‰‹ç¦»æ‘„åƒå¤´è¿œè¿‘(å¤§å°)ï¼Œç‰¹å¾éƒ½ä¸€æ ·ã€‚
    """
    # æ·±æ‹·è´ï¼Œé˜²æ­¢ä¿®æ”¹åŸå§‹æ•°æ®
    temp_landmark_list = copy.deepcopy(landmarks)

    # --- 1. è½¬æ¢ä¸ºç›¸å¯¹åæ ‡ (Relative Coordinates) ---
    base_x, base_y, base_z = 0, 0, 0
    for index, landmark_point in enumerate(temp_landmark_list):
        if index == 0:
            # è·å–æ‰‹è…•(Wrist)çš„åæ ‡ä½œä¸ºåŸºå‡†ç‚¹
            base_x, base_y, base_z = landmark_point[0], landmark_point[1], landmark_point[2]

        # æ‰€æœ‰ç‚¹å‡å»åŸºå‡†ç‚¹
        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x
        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y
        temp_landmark_list[index][2] = temp_landmark_list[index][2] - base_z

    # --- 2. å°ºåº¦å½’ä¸€åŒ– (Normalization) ---
    # å°†æ‰€æœ‰åæ ‡å€¼ç¼©æ”¾åˆ° -1 åˆ° 1 ä¹‹é—´
    # å±•å¹³åˆ—è¡¨ä»¥æ‰¾åˆ°æœ€å¤§ç»å¯¹å€¼ (åªè€ƒè™‘ x å’Œ yï¼Œå› ä¸º z çš„æ¯”ä¾‹å°ºå¯èƒ½ä¸åŒï¼Œæˆ–è€…ä¹Ÿä¸€èµ·å½’ä¸€åŒ–)
    flattened = [val for sublist in temp_landmark_list for val in sublist]
    max_value = max(list(map(abs, flattened)))

    def normalize_(n):
        return n / max_value if max_value != 0 else 0

    # ç”Ÿæˆæœ€ç»ˆçš„ç‰¹å¾åˆ—è¡¨
    final_features = []
    for lm in temp_landmark_list:
        # å¯¹ x, y, z éƒ½è¿›è¡Œå½’ä¸€åŒ–
        final_features.extend([normalize_(lm[0]), normalize_(lm[1]), normalize_(lm[2])])

    return final_features


def process_dataset():
    data = []

    # 1. æ£€æŸ¥æ•°æ®æ–‡ä»¶å¤¹
    if not os.path.exists(DATA_DIR):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶å¤¹ '{DATA_DIR}'ã€‚è¯·ç¡®ä¿å›¾ç‰‡æ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•ä¸‹ï¼")
        return

    # è·å–æ‰€æœ‰ç±»åˆ« (A, B, C...)
    # è¿‡æ»¤æ‰éšè—æ–‡ä»¶ (å¦‚ .DS_Store)
    classes = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])
    print(f"ğŸ“‚ å‘ç°ç±»åˆ«: {classes}")

    total_images = 0
    valid_images = 0

    # 2. éå†æ¯ä¸ªç±»åˆ«çš„æ–‡ä»¶å¤¹
    for class_name in classes:
        class_path = os.path.join(DATA_DIR, class_name)
        file_names = os.listdir(class_path)

        print(f"æ­£åœ¨å¤„ç†ç±»åˆ« ã€{class_name}ã€‘...")

        for file_name in file_names:
            # åªå¤„ç†å›¾ç‰‡æ–‡ä»¶
            if not file_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                continue

            total_images += 1
            image_path = os.path.join(class_path, file_name)

            # è¯»å–å›¾ç‰‡
            img = cv2.imread(image_path)
            if img is None:
                continue

            # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            # MediaPipe å¤„ç†
            results = hands.process(img_rgb)

            # --- 3. æ•°æ®æ¸…æ´— (Data Cleaning) [cite: 161] ---
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ‰‹ï¼Œåˆ™è·³è¿‡(è§†ä¸ºå™ªå£°æ•°æ®)ï¼Œè¿™å°±æ˜¯æ–‡æ¡£è¦æ±‚çš„ Cleaning
            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0]

                # æå–åŸå§‹åæ ‡ (x, y, z)
                raw_landmarks = []
                for lm in hand_landmarks.landmark:
                    raw_landmarks.append([lm.x, lm.y, lm.z])

                # ğŸ”¥ è°ƒç”¨å½’ä¸€åŒ–å‡½æ•° (Pre-processing å¾—åˆ†ç‚¹)
                processed_features = normalize_landmarks(raw_landmarks)

                # æ·»åŠ åˆ°æ•°æ®åˆ—è¡¨: [Label, Feature1, Feature2 ... Feature63]
                row = [class_name] + processed_features
                data.append(row)
                valid_images += 1
            else:
                # å¯ä»¥åœ¨è¿™é‡Œæ‰“å°æ—¥å¿—ï¼Œè¯æ˜ä½ åšäº†æ¸…æ´—
                pass

    # 4. ä¿å­˜ä¸º CSV
    if data:
        # ç”Ÿæˆè¡¨å¤´
        header = ['label']
        for i in range(21):
            header.extend([f'x{i}', f'y{i}', f'z{i}'])

        df = pd.DataFrame(data, columns=header)
        df.to_csv(OUTPUT_FILE, index=False)

        print("-" * 40)
        print(f"ğŸ‰ ç‰¹å¾æå–ä¸é¢„å¤„ç†å®Œæˆï¼")
        print(f"åŸå§‹å›¾ç‰‡: {total_images} å¼ ")
        print(f"æ¸…æ´—åæœ‰æ•ˆæ•°æ®: {valid_images} æ¡")
        print(f"æ•°æ®å·²ä¿å­˜è‡³: {OUTPUT_FILE}")
        print("-" * 40)
    else:
        print("âŒ æœªæå–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡è·¯å¾„ã€‚")


if __name__ == "__main__":
    process_dataset()
    hands.close()